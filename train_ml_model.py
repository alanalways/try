# -*- coding: utf-8 -*-
"""
ML æ¨¡å‹è¨“ç·´è…³æœ¬ (Research Notebook)
åœ¨ QuantConnect Research ç’°å¢ƒä¸­é‹è¡Œ

ä½¿ç”¨æ–¹å¼:
1. åœ¨ QuantConnect æ‰“é–‹ Research Notebook
2. å°‡æ­¤æª”æ¡ˆå…§å®¹è¤‡è£½åˆ° Notebook
3. é€å€‹ Cell åŸ·è¡Œ
"""

# ============================================================
# Cell 1: å°å…¥èˆ‡åˆå§‹åŒ–
# ============================================================

from AlgorithmImports import *
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
import pickle

# åˆå§‹åŒ– QuantBook (Research å°ˆç”¨)
qb = QuantBook()

# è¨­å®šåƒæ•¸
SYMBOL = "BTCUSDT"
START_DATE = datetime(2022, 1, 1)
END_DATE = datetime(2024, 1, 1)
MODEL_NAME = "harmonic_smc_rf_model.pkl"

print("âœ… åˆå§‹åŒ–å®Œæˆ")


# ============================================================
# Cell 2: ç²å–æ­·å²æ•¸æ“š
# ============================================================

# æ·»åŠ äº¤æ˜“å°
symbol = qb.AddCrypto(SYMBOL, Resolution.Hour).Symbol

# ç²å–æ­·å²æ•¸æ“š
history = qb.History(symbol, START_DATE, END_DATE, Resolution.Hour)

# è½‰æ›ç‚ºæ¨™æº– DataFrame
if isinstance(history.index, pd.MultiIndex):
    df = history.loc[symbol].copy()
else:
    df = history.copy()

df.index = pd.to_datetime(df.index)
print(f"âœ… ç²å–æ•¸æ“š: {len(df)} è¡Œ")
print(df.tail())


# ============================================================
# Cell 3: æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
# ============================================================

def add_indicators(df):
    """æ·»åŠ æŠ€è¡“æŒ‡æ¨™"""
    # RSI
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    # EMA
    df['ema_50'] = df['close'].ewm(span=50, adjust=False).mean()
    df['ema_200'] = df['close'].ewm(span=200, adjust=False).mean()
    
    # ATR
    high_low = df['high'] - df['low']
    high_close = abs(df['high'] - df['close'].shift())
    low_close = abs(df['low'] - df['close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['atr'] = tr.rolling(window=14).mean()
    
    # Bollinger Bands
    df['bb_middle'] = df['close'].rolling(window=20).mean()
    bb_std = df['close'].rolling(window=20).std()
    df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
    df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
    
    # Volume SMA
    df['volume_sma'] = df['volume'].rolling(window=20).mean()
    
    # Trend
    df['trend'] = np.where(df['ema_50'] > df['ema_200'], 1, -1)
    
    return df

df = add_indicators(df)
print("âœ… æŒ‡æ¨™è¨ˆç®—å®Œæˆ")


# ============================================================
# Cell 4: ZigZag è¨ˆç®—
# ============================================================

def calculate_zigzag(df, min_retrace_pct=1.0):
    """è¨ˆç®— ZigZag æ“ºå‹•é»"""
    swing_points = []
    last_swing = None
    last_swing_type = None
    
    for i in range(3, len(df)):
        current_high = df['high'].iloc[i]
        current_low = df['low'].iloc[i]
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ½›åœ¨é«˜é»
        is_high = all(
            df['high'].iloc[i-j] <= current_high 
            for j in range(1, 4)
        )
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ½›åœ¨ä½é»
        is_low = all(
            df['low'].iloc[i-j] >= current_low 
            for j in range(1, 4)
        )
        
        if is_high and (last_swing_type != 'high'):
            lookback = min(20, i)
            recent_low = df['low'].iloc[i-lookback:i].min()
            retrace = (current_high - recent_low) / recent_low * 100
            
            if retrace >= min_retrace_pct:
                swing_points.append({
                    'index': i,
                    'price': current_high,
                    'type': 'high',
                    'time': df.index[i]
                })
                last_swing = current_high
                last_swing_type = 'high'
        
        if is_low and (last_swing_type != 'low'):
            lookback = min(20, i)
            recent_high = df['high'].iloc[i-lookback:i].max()
            retrace = (recent_high - current_low) / recent_high * 100
            
            if retrace >= min_retrace_pct:
                swing_points.append({
                    'index': i,
                    'price': current_low,
                    'type': 'low',
                    'time': df.index[i]
                })
                last_swing = current_low
                last_swing_type = 'low'
    
    return swing_points

swing_points = calculate_zigzag(df)
print(f"âœ… æ‰¾åˆ° {len(swing_points)} å€‹æ“ºå‹•é»")


# ============================================================
# Cell 5: ç‰¹å¾µç”Ÿæˆå‡½æ•¸
# ============================================================

def generate_features_at_point(df, point_index, lookback=50):
    """åœ¨æŒ‡å®šé»ç”Ÿæˆç‰¹å¾µ"""
    if point_index < lookback:
        return None
    
    try:
        current = df.iloc[point_index]
        recent = df.iloc[point_index-lookback:point_index]
        
        # RSI ç›¸é—œ
        rsi = current['rsi'] if not pd.isna(current['rsi']) else 50
        
        # è¶¨å‹¢å°é½Š
        trend = current['trend'] if 'trend' in df.columns else 0
        
        # æ³¢å‹•æ€§
        atr = current['atr'] if not pd.isna(current['atr']) else 0
        atr_norm = atr / current['close'] if current['close'] > 0 else 0
        
        # å¸ƒæ—å¸¶ä½ç½®
        if not pd.isna(current['bb_upper']) and not pd.isna(current['bb_lower']):
            bb_range = current['bb_upper'] - current['bb_lower']
            bb_pos = (current['close'] - current['bb_lower']) / bb_range if bb_range > 0 else 0.5
        else:
            bb_pos = 0.5
        
        # æˆäº¤é‡ç•°å¸¸
        vol_sma = current['volume_sma'] if not pd.isna(current['volume_sma']) else current['volume']
        vol_spike = 1 if current['volume'] > vol_sma * 1.5 else 0
        
        # EMA è·é›¢
        ema_dist = (current['close'] - current['ema_50']) / current['close'] if current['close'] > 0 else 0
        
        # åƒ¹æ ¼å‹•é‡
        momentum = (current['close'] - recent['close'].iloc[0]) / recent['close'].iloc[0] if recent['close'].iloc[0] > 0 else 0
        
        # æ³¢å‹•æ€§è®ŠåŒ–
        vol_recent = recent['atr'].iloc[-10:].mean() if len(recent) >= 10 else atr
        vol_older = recent['atr'].iloc[:10].mean() if len(recent) >= 10 else atr
        vol_change = (vol_recent - vol_older) / vol_older if vol_older > 0 else 0
        
        return {
            'rsi': rsi,
            'trend': trend,
            'atr_norm': atr_norm,
            'bb_pos': bb_pos,
            'vol_spike': vol_spike,
            'ema_dist': ema_dist,
            'momentum': momentum,
            'vol_change': vol_change
        }
    
    except Exception as e:
        return None

print("âœ… ç‰¹å¾µç”Ÿæˆå‡½æ•¸å®šç¾©å®Œæˆ")


# ============================================================
# Cell 6: ç”Ÿæˆè¨“ç·´æ•¸æ“šé›†
# ============================================================

def generate_training_data(df, swing_points, lookahead=20, profit_threshold=0.015):
    """
    ç”Ÿæˆè¨“ç·´æ•¸æ“š
    
    lookahead: å‘å‰çœ‹å¤šå°‘æ ¹Kç·šä¾†ç¢ºå®šçµæœ
    profit_threshold: ç²åˆ©é–¾å€¼ (1.5%)
    """
    features_list = []
    labels = []
    
    for sp in swing_points:
        idx = sp['index']
        
        # ç¢ºä¿æœ‰è¶³å¤ çš„å‰å‘æ•¸æ“š
        if idx + lookahead >= len(df):
            continue
        
        # ç”Ÿæˆç‰¹å¾µ
        features = generate_features_at_point(df, idx)
        if features is None:
            continue
        
        # ç¢ºå®šæ¨™ç±¤ (æœªä¾† lookahead æ ¹ K ç·šçš„è¡¨ç¾)
        entry_price = df['close'].iloc[idx]
        future_prices = df['close'].iloc[idx+1:idx+lookahead+1]
        
        if sp['type'] == 'low':  # æ½›åœ¨çœ‹æ¼²ä¿¡è™Ÿ
            max_profit = (future_prices.max() - entry_price) / entry_price
            max_loss = (entry_price - future_prices.min()) / entry_price
        else:  # æ½›åœ¨çœ‹è·Œä¿¡è™Ÿ
            max_profit = (entry_price - future_prices.min()) / entry_price
            max_loss = (future_prices.max() - entry_price) / entry_price
        
        # æ¨™ç±¤: 1 = æˆåŠŸ (ç²åˆ© > é–¾å€¼ ä¸” é¢¨éšªå ±é…¬ > 1.5)
        # æ¨™ç±¤: 0 = å¤±æ•—
        risk_reward = max_profit / max_loss if max_loss > 0 else 0
        
        if max_profit >= profit_threshold and risk_reward >= 1.5:
            label = 1
        else:
            label = 0
        
        # æ·»åŠ æ–¹å‘ç‰¹å¾µ
        features['is_bullish'] = 1 if sp['type'] == 'low' else 0
        
        features_list.append(features)
        labels.append(label)
    
    return pd.DataFrame(features_list), labels

# ç”Ÿæˆè¨“ç·´æ•¸æ“š
X, y = generate_training_data(df, swing_points)
print(f"âœ… ç”Ÿæˆè¨“ç·´æ•¸æ“š: {len(X)} æ¨£æœ¬")
print(f"æ­£æ¨£æœ¬ (æˆåŠŸäº¤æ˜“): {sum(y)} ({sum(y)/len(y)*100:.1f}%)")
print(f"è² æ¨£æœ¬ (å¤±æ•—äº¤æ˜“): {len(y)-sum(y)} ({(len(y)-sum(y))/len(y)*100:.1f}%)")


# ============================================================
# Cell 7: è¨“ç·´æ¨¡å‹
# ============================================================

# åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# åˆå§‹åŒ– RandomForest
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight='balanced',  # è™•ç†é¡åˆ¥ä¸å¹³è¡¡
    random_state=42,
    n_jobs=-1
)

# è¨“ç·´
model.fit(X_train, y_train)
print("âœ… æ¨¡å‹è¨“ç·´å®Œæˆ")

# è©•ä¼°
train_score = model.score(X_train, y_train)
test_score = model.score(X_test, y_test)
print(f"è¨“ç·´é›†æº–ç¢ºç‡: {train_score:.4f}")
print(f"æ¸¬è©¦é›†æº–ç¢ºç‡: {test_score:.4f}")

# äº¤å‰é©—è­‰
cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f"äº¤å‰é©—è­‰æº–ç¢ºç‡: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})")


# ============================================================
# Cell 8: è©³ç´°è©•ä¼°å ±å‘Š
# ============================================================

# é æ¸¬
y_pred = model.predict(X_test)

# åˆ†é¡å ±å‘Š
print("\nğŸ“Š åˆ†é¡å ±å‘Š:")
print(classification_report(y_test, y_pred, target_names=['å¤±æ•—', 'æˆåŠŸ']))

# æ··æ·†çŸ©é™£
print("\nğŸ“Š æ··æ·†çŸ©é™£:")
cm = confusion_matrix(y_test, y_pred)
print(cm)

# ç‰¹å¾µé‡è¦æ€§
print("\nğŸ“Š ç‰¹å¾µé‡è¦æ€§:")
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)
print(feature_importance)


# ============================================================
# Cell 9: ä¿å­˜æ¨¡å‹åˆ° ObjectStore
# ============================================================

# åºåˆ—åŒ–æ¨¡å‹
model_bytes = pickle.dumps(model)

# ä¿å­˜åˆ° ObjectStore
qb.ObjectStore.SaveBytes(MODEL_NAME, model_bytes)
print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ° ObjectStore: {MODEL_NAME}")

# é©—è­‰ä¿å­˜
if qb.ObjectStore.ContainsKey(MODEL_NAME):
    print("âœ… æ¨¡å‹é©—è­‰æˆåŠŸï¼Œå¯åœ¨ç­–ç•¥ä¸­ä½¿ç”¨")
else:
    print("âŒ æ¨¡å‹ä¿å­˜é©—è­‰å¤±æ•—")


# ============================================================
# Cell 10: æ¸¬è©¦è¼‰å…¥æ¨¡å‹
# ============================================================

# è®€å–æ¨¡å‹
loaded_bytes = qb.ObjectStore.ReadBytes(MODEL_NAME)
loaded_model = pickle.loads(loaded_bytes)

# æ¸¬è©¦é æ¸¬
test_prediction = loaded_model.predict_proba(X_test.iloc[:5])
print("âœ… æ¨¡å‹è¼‰å…¥æ¸¬è©¦æˆåŠŸ")
print("æ¸¬è©¦é æ¸¬æ¦‚ç‡:")
print(test_prediction)


# ============================================================
# Cell 11: å¯è¦–åŒ– (å¯é¸)
# ============================================================

"""
# å¦‚æœåœ¨ Jupyter Notebook ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç¢¼å¯è¦–åŒ–

import matplotlib.pyplot as plt

# ç‰¹å¾µé‡è¦æ€§åœ–
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['feature'], feature_importance['importance'])
plt.xlabel('Importance')
plt.title('Feature Importance')
plt.tight_layout()
plt.show()

# åƒ¹æ ¼å’Œæ“ºå‹•é»
plt.figure(figsize=(15, 6))
plt.plot(df.index, df['close'], label='Close')

swing_highs = [sp for sp in swing_points if sp['type'] == 'high']
swing_lows = [sp for sp in swing_points if sp['type'] == 'low']

plt.scatter([sp['time'] for sp in swing_highs], 
            [sp['price'] for sp in swing_highs], 
            color='red', marker='v', s=100, label='Swing High')
plt.scatter([sp['time'] for sp in swing_lows], 
            [sp['price'] for sp in swing_lows], 
            color='green', marker='^', s=100, label='Swing Low')

plt.legend()
plt.title('Price with Swing Points')
plt.tight_layout()
plt.show()
"""

print("""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‰ ML è¨“ç·´å®Œæˆï¼

ä¸‹ä¸€æ­¥:
1. åœ¨ QuantConnect ç­–ç•¥ä¸­ï¼Œæ¨¡å‹æœƒè‡ªå‹•å¾ ObjectStore è¼‰å…¥
2. ç¢ºä¿ config.py ä¸­çš„ ML_MODEL_NAME èˆ‡é€™è£¡ä¸€è‡´
3. é‹è¡Œå›æ¸¬é©—è­‰ç­–ç•¥æ•ˆæœ

æç¤º:
- å¦‚æœå‹ç‡åä½ï¼Œå˜—è©¦èª¿æ•´ profit_threshold
- å¦‚æœæ¨£æœ¬ä¸å¹³è¡¡ï¼Œå¯ä»¥ä½¿ç”¨ SMOTE éæ¡æ¨£
- å®šæœŸé‡æ–°è¨“ç·´æ¨¡å‹ä»¥é©æ‡‰å¸‚å ´è®ŠåŒ–
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""")

